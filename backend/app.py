#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
BioInfo Search System - åç«¯ä¸»åº”ç”¨
åŸºäºFastAPIçš„ç”Ÿç‰©ä¿¡æ¯æ™ºèƒ½æ£€ç´¢ç³»ç»Ÿ
"""

import os
import sys
import json
import asyncio
from datetime import datetime
from typing import Optional, List, Dict, Any
from contextlib import asynccontextmanager

from fastapi import FastAPI, HTTPException, BackgroundTasks, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, JSONResponse
from pydantic import BaseModel, Field

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from services.llm_parser import LLMQueryParser
from services.enhanced_data_fetcher import EnhancedBioDataFetcher, EnhancedDataSourceRegistry
from services.data_cleaner import DataCleaningService
from services.database import DatabaseManager
from services.task_manager import TaskManager

# é…ç½®
DATA_DIR = os.environ.get("DATA_DIR", "/app/data")
OLLAMA_HOST = os.environ.get("OLLAMA_HOST", "http://localhost:11434")
DB_PATH = os.environ.get("DB_PATH", "/app/data/bioinfo.db")

# å…¨å±€ä»»åŠ¡ç®¡ç†å™¨
task_manager = TaskManager()

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    # å¯åŠ¨æ—¶åˆå§‹åŒ–
    os.makedirs(DATA_DIR, exist_ok=True)
    os.makedirs(f"{DATA_DIR}/exports", exist_ok=True)
    os.makedirs(f"{DATA_DIR}/logs", exist_ok=True)
    
    # åˆå§‹åŒ–æ•°æ®åº“
    db = DatabaseManager(DB_PATH)
    await db.init_db()
    app.state.db = db
    
    # åˆå§‹åŒ–LLMè§£æå™¨
    app.state.llm_parser = LLMQueryParser(OLLAMA_HOST)
    
    # åˆå§‹åŒ–æ•°æ®è·å–å™¨ï¼ˆå¢å¼ºç‰ˆï¼‰
    app.state.data_fetcher = EnhancedBioDataFetcher()
    
    # åˆå§‹åŒ–æ•°æ®æ¸…æ´—æœåŠ¡
    app.state.data_cleaner = DataCleaningService()
    
    print("ğŸš€ BioInfo Search System å¯åŠ¨æˆåŠŸ!")
    print(f"ğŸ“ æ•°æ®ç›®å½•: {DATA_DIR}")
    print(f"ğŸ¤– Ollama åœ°å€: {OLLAMA_HOST}")
    
    yield
    
    # å…³é—­æ—¶æ¸…ç†
    await db.close()
    print("ğŸ‘‹ BioInfo Search System å·²å…³é—­")

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="BioInfo Search System",
    description="åŸºäºLLMçš„ç”Ÿç‰©ä¿¡æ¯æ™ºèƒ½æ£€ç´¢ç³»ç»Ÿ",
    version="1.0.0",
    lifespan=lifespan
)

# CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==================== æ•°æ®æ¨¡å‹ ====================

class SearchRequest(BaseModel):
    """æœç´¢è¯·æ±‚æ¨¡å‹"""
    query: str = Field(..., description="è‡ªç„¶è¯­è¨€æŸ¥è¯¢", min_length=2, max_length=1000)
    max_results: int = Field(default=100, ge=1, le=1000, description="æœ€å¤§ç»“æœæ•°")
    sources: List[str] = Field(default=["clinicaltrials", "pubmed"], description="æ•°æ®æº")
    use_llm: bool = Field(default=True, description="æ˜¯å¦ä½¿ç”¨LLMè§£æ")

class SearchResponse(BaseModel):
    """æœç´¢å“åº”æ¨¡å‹"""
    task_id: str
    status: str
    message: str
    parsed_query: Optional[Dict] = None

class TaskStatusResponse(BaseModel):
    """ä»»åŠ¡çŠ¶æ€å“åº”"""
    task_id: str
    status: str
    progress: float
    message: str
    result: Optional[Dict] = None
    error: Optional[str] = None

class DataExportRequest(BaseModel):
    """æ•°æ®å¯¼å‡ºè¯·æ±‚"""
    task_id: str
    format: str = Field(default="csv", pattern="^(csv|xlsx|json)$")

class HistoryQuery(BaseModel):
    """å†å²æŸ¥è¯¢"""
    page: int = Field(default=1, ge=1)
    page_size: int = Field(default=20, ge=1, le=100)
    keyword: Optional[str] = None

# ==================== APIè·¯ç”± ====================

@app.get("/")
async def root():
    """æ ¹è·¯ç”± - ç³»ç»Ÿä¿¡æ¯"""
    return {
        "name": "BioInfo Search System",
        "version": "1.0.0",
        "description": "åŸºäºLLMçš„ç”Ÿç‰©ä¿¡æ¯æ™ºèƒ½æ£€ç´¢ç³»ç»Ÿ",
        "endpoints": {
            "search": "/api/search",
            "status": "/api/task/{task_id}",
            "history": "/api/history",
            "export": "/api/export"
        }
    }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "ollama_status": await app.state.llm_parser.check_connection()
    }

@app.get("/api/sources")
async def get_available_sources():
    """è·å–å¯ç”¨æ•°æ®æºåˆ—è¡¨"""
    return {
        "sources": EnhancedDataSourceRegistry.get_available_sources(),
        "categories": {
            "clinical_trials": EnhancedDataSourceRegistry.get_sources_by_category("clinical_trials"),
            "literature": EnhancedDataSourceRegistry.get_sources_by_category("literature")
        }
    }

@app.post("/api/search", response_model=SearchResponse)
async def search(request: SearchRequest, background_tasks: BackgroundTasks):
    """
    æ‰§è¡Œç”Ÿç‰©ä¿¡æ¯æœç´¢
    
    1. ä½¿ç”¨LLMè§£æè‡ªç„¶è¯­è¨€æŸ¥è¯¢
    2. è°ƒç”¨ç›¸åº”APIè·å–æ•°æ®
    3. æ¸…æ´—å’Œæ•´åˆæ•°æ®
    4. ä¿å­˜åˆ°æ•°æ®åº“
    """
    try:
        # åˆ›å»ºä»»åŠ¡
        task_id = task_manager.create_task(request.query)
        
        # å¦‚æœä½¿ç”¨LLMï¼Œå…ˆè§£ææŸ¥è¯¢
        parsed_query = None
        if request.use_llm:
            try:
                parsed_query = await app.state.llm_parser.parse_query(request.query)
                task_manager.update_task(task_id, progress=0.1, message="æŸ¥è¯¢è§£æå®Œæˆ")
            except Exception as e:
                # LLMè§£æå¤±è´¥ï¼Œä½¿ç”¨ç®€å•è§£æ
                parsed_query = {"keywords": request.query.split(), "original": request.query}
                task_manager.update_task(task_id, progress=0.1, message=f"ä½¿ç”¨ç®€å•è§£æ: {str(e)}")
        else:
            parsed_query = {"keywords": request.query.split(), "original": request.query}
        
        # åœ¨åå°æ‰§è¡Œæ•°æ®è·å–ä»»åŠ¡
        background_tasks.add_task(
            execute_search_task,
            task_id=task_id,
            parsed_query=parsed_query,
            sources=request.sources,
            max_results=request.max_results,
            db=app.state.db,
            fetcher=app.state.data_fetcher,
            cleaner=app.state.data_cleaner
        )
        
        return SearchResponse(
            task_id=task_id,
            status="processing",
            message="æœç´¢ä»»åŠ¡å·²åˆ›å»ºï¼Œæ­£åœ¨åå°å¤„ç†",
            parsed_query=parsed_query
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

async def execute_search_task(
    task_id: str,
    parsed_query: Dict,
    sources: List[str],
    max_results: int,
    db: DatabaseManager,
    fetcher: EnhancedBioDataFetcher,
    cleaner: DataCleaningService
):
    """åå°æ‰§è¡Œæœç´¢ä»»åŠ¡"""
    try:
        # è·å–å…³é”®è¯
        keywords = parsed_query.get("keywords", [])
        condition = parsed_query.get("condition", "")
        search_term = condition if condition else " ".join(keywords)
        
        if not search_term:
            search_term = parsed_query.get("original", "")
        
        # ä½¿ç”¨èšåˆæœç´¢æ–¹æ³•è·å–æ‰€æœ‰æ•°æ®æºçš„æ•°æ®
        task_manager.update_task(
            task_id, 
            progress=0.2,
            message=f"æ­£åœ¨ä» {len(sources)} ä¸ªæ•°æ®æºè·å–æ•°æ®..."
        )
        
        # è°ƒç”¨å¢å¼ºç‰ˆæ•°æ®è·å–å™¨çš„èšåˆæœç´¢æ–¹æ³•
        raw_results = await fetcher.fetch_all(
            search_term=search_term,
            sources=sources,
            max_results=max_results,
            enrich_oa=True  # è‡ªåŠ¨æ·»åŠ å¼€æ”¾è·å–ä¿¡æ¯
        )
        
        # è½¬æ¢ç»“æœæ ¼å¼
        all_results = []
        for source, data in raw_results.items():
            task_manager.update_task(
                task_id, 
                progress=0.4,
                message=f"å·²è·å– {source} æ•°æ®: {len(data)} æ¡"
            )
            all_results.append({
                "source": source,
                "data": data,
                "count": len(data) if data else 0
            })
        
        # æ•°æ®æ¸…æ´—
        task_manager.update_task(task_id, progress=0.7, message="æ­£åœ¨æ¸…æ´—æ•°æ®...")
        cleaned_results = []
        for result in all_results:
            if result["data"]:
                cleaned_data = cleaner.clean_data(result["data"], result["source"])
                cleaned_results.append({
                    "source": result["source"],
                    "data": cleaned_data,
                    "count": len(cleaned_data),
                    "original_count": result["count"]
                })
            else:
                cleaned_results.append(result)
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        task_manager.update_task(task_id, progress=0.9, message="æ­£åœ¨ä¿å­˜æ•°æ®...")
        search_record_id = await db.save_search_record(
            query=parsed_query.get("original", search_term),
            parsed_query=parsed_query,
            results=cleaned_results
        )
        
        # å®Œæˆä»»åŠ¡
        summary = {
            "search_id": search_record_id,
            "total_results": sum(r["count"] for r in cleaned_results),
            "sources": {r["source"]: r["count"] for r in cleaned_results},
            "query": parsed_query
        }
        
        task_manager.complete_task(task_id, summary)
        
    except Exception as e:
        task_manager.fail_task(task_id, str(e))

@app.get("/api/task/{task_id}", response_model=TaskStatusResponse)
async def get_task_status(task_id: str):
    """è·å–ä»»åŠ¡çŠ¶æ€"""
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    return TaskStatusResponse(
        task_id=task_id,
        status=task["status"],
        progress=task["progress"],
        message=task["message"],
        result=task.get("result"),
        error=task.get("error")
    )

@app.get("/api/history")
async def get_search_history(page: int = 1, page_size: int = 20, keyword: Optional[str] = None):
    """è·å–æœç´¢å†å²"""
    try:
        history = await app.state.db.get_search_history(page, page_size, keyword)
        return history
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/search/{search_id}")
async def get_search_detail(search_id: int):
    """è·å–æœç´¢è¯¦æƒ…"""
    try:
        detail = await app.state.db.get_search_detail(search_id)
        if not detail:
            raise HTTPException(status_code=404, detail="æœç´¢è®°å½•ä¸å­˜åœ¨")
        return detail
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/export")
async def export_data(request: DataExportRequest):
    """å¯¼å‡ºæ•°æ®"""
    try:
        # è·å–ä»»åŠ¡ç»“æœ
        task = task_manager.get_task(request.task_id)
        if not task:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
        
        if task["status"] != "completed":
            raise HTTPException(status_code=400, detail="ä»»åŠ¡å°šæœªå®Œæˆ")
        
        # è·å–æœç´¢ç»“æœ
        search_id = task["result"]["search_id"]
        detail = await app.state.db.get_search_detail(search_id)
        
        # å¯¼å‡ºæ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"bioinfo_export_{timestamp}.{request.format}"
        filepath = f"{DATA_DIR}/exports/{filename}"
        
        if request.format == "csv":
            await export_to_csv(detail["results"], filepath)
        elif request.format == "xlsx":
            await export_to_xlsx(detail["results"], filepath)
        elif request.format == "json":
            await export_to_json(detail["results"], filepath)
        
        return {
            "status": "success",
            "filename": filename,
            "download_url": f"/api/download/{filename}"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/export/{search_id}")
async def export_by_search_id(search_id: int, format: str = "csv"):
    """æ ¹æ®æœç´¢IDå¯¼å‡ºæ•°æ®"""
    try:
        # éªŒè¯æ ¼å¼
        if format not in ["csv", "xlsx", "json"]:
            raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼")
        
        # è·å–æœç´¢ç»“æœ
        detail = await app.state.db.get_search_detail(search_id)
        if not detail:
            raise HTTPException(status_code=404, detail="æœç´¢è®°å½•ä¸å­˜åœ¨")
        
        # å¯¼å‡ºæ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"bioinfo_export_{timestamp}.{format}"
        filepath = f"{DATA_DIR}/exports/{filename}"
        
        if format == "csv":
            await export_to_csv(detail["results"], filepath)
        elif format == "xlsx":
            await export_to_xlsx(detail["results"], filepath)
        elif format == "json":
            await export_to_json(detail["results"], filepath)
        
        return {
            "status": "success",
            "filename": filename,
            "download_url": f"/api/download/{filename}"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/download/{filename}")
async def download_file(filename: str):
    """ä¸‹è½½å¯¼å‡ºçš„æ–‡ä»¶"""
    filepath = f"{DATA_DIR}/exports/{filename}"
    if not os.path.exists(filepath):
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
    return FileResponse(filepath, filename=filename)

@app.delete("/api/search/{search_id}")
async def delete_search_record(search_id: int):
    """åˆ é™¤æœç´¢è®°å½•"""
    try:
        await app.state.db.delete_search_record(search_id)
        return {"status": "success", "message": "åˆ é™¤æˆåŠŸ"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/stats")
async def get_statistics():
    """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
    try:
        stats = await app.state.db.get_statistics()
        return stats
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ==================== WebSocketå®æ—¶æ›´æ–° ====================

@app.websocket("/ws/task/{task_id}")
async def websocket_task_status(websocket: WebSocket, task_id: str):
    """WebSocketå®æ—¶ä»»åŠ¡çŠ¶æ€æ›´æ–°"""
    await websocket.accept()
    try:
        while True:
            task = task_manager.get_task(task_id)
            if task:
                await websocket.send_json(task)
                if task["status"] in ["completed", "failed"]:
                    break
            await asyncio.sleep(0.5)
    except WebSocketDisconnect:
        pass

# ==================== è¾…åŠ©å‡½æ•° ====================

async def export_to_csv(results: List[Dict], filepath: str):
    """å¯¼å‡ºä¸ºCSV"""
    import pandas as pd
    all_data = []
    for source_result in results:
        for item in source_result.get("data", []):
            item["_source"] = source_result["source"]
            all_data.append(item)
    
    if all_data:
        df = pd.DataFrame(all_data)
        df.to_csv(filepath, index=False, encoding='utf-8-sig')

async def export_to_xlsx(results: List[Dict], filepath: str):
    """å¯¼å‡ºä¸ºExcel"""
    import pandas as pd
    with pd.ExcelWriter(filepath, engine='openpyxl') as writer:
        for source_result in results:
            source = source_result["source"]
            data = source_result.get("data", [])
            if data:
                df = pd.DataFrame(data)
                df.to_excel(writer, sheet_name=source[:31], index=False)

async def export_to_json(results: List[Dict], filepath: str):
    """å¯¼å‡ºä¸ºJSON"""
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2, default=str)

# ==================== å¯åŠ¨å…¥å£ ====================

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "app:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )